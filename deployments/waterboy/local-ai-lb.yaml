---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: models-pvc
  namespace: local-ai
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-ai
  namespace: local-ai
  labels:
    app: local-ai
spec:
  selector:
    matchLabels:
      app: local-ai
  replicas: 2
  template:
    metadata:
      labels:
        app: local-ai
      name: local-ai
    spec:
      runtimeClassName: "nvidia"
      containers:
        - args:
          - hermes-3-llama-3.1-8b:vllm
          envFrom:
          - secretRef:
              name: env-secrets
          name: local-ai
          image: quay.io/go-skynet/local-ai:master-cublas-cuda12
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: models-volume
              mountPath: /build/models
      volumes:
        - name: models-volume
          persistentVolumeClaim:
            claimName: models-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: local-ai
  namespace: local-ai
spec:
  selector:
    app: local-ai
  type: NodePort
  ports:
    - protocol: TCP
      targetPort: 8080
      port: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: local-ai-lb
  namespace: local-ai
spec:
  selector:
    app: local-ai
  type: LoadBalancer
  ports:
    - protocol: TCP
      targetPort: 8080
      port: 80