model_list:

  # vllm-0-hermes
  - model_name: NousResearch/Hermes-3-Llama-3.1-8B
    litellm_params:
      model: openai/NousResearch/Hermes-3-Llama-3.1-8B
      api_base: http://vllm-0-hermes:8000/v1
      api_key: none

  # vllm-1-qwen25
  - model_name: Qwen/Qwen2.5-7B-Instruct
    litellm_params:
      model: openai/Qwen/Qwen2.5-7B-Instruct
      api_base: http://vllm-1-qwen25:8000/v1
      api_key: none

  # vllm-2-llama31
  - model_name: meta-llama/Llama-3.1-8B-Instruct
    litellm_params:
      model: openai/meta-llama/Llama-3.1-8B-Instruct
      api_base: http://vllm-2-llama31:8000/v1
      api_key: none

  # vllm-3-toolace
  - model_name: Team-ACE/ToolACE-8B
    litellm_params:
      model: openai/Team-ACE/ToolACE-8B
      api_base: http://vllm-3-toolace:8000/v1
      api_key: none

  # vllm-4-minicpm3
  - model_name: openbmb/MiniCPM3-4B
    litellm_params:
      model: openai/openbmb/MiniCPM3-4B
      api_base: http://vllm-4-minicpm3:8000/v1
      api_key: none

  # vllm-5-mistral
  - model_name: mistralai/Mistral-7B-Instruct-v0.3
    litellm_params:
      model: openai/mistralai/Mistral-7B-Instruct-v0.3
      api_base: http://vllm-5-mistral:8000/v1
      api_key: none
      temperature: 0 # required for mistral function calling

  # vllm-6-internlm
  - model_name: internlm/internlm2_5-7b-chat
    litellm_params:
      model: openai/internlm/internlm2_5-7b-chat
      api_base: http://vllm-6-internlm:8000/v1
      api_key: none

  # vllm-7-functionary31
  - model_name: meetkai/functionary-small-v3.1
    litellm_params:
      model: openai/meetkai/functionary-small-v3.1
      api_base: http://vllm-7-functionary31:8000/v1
      api_key: none

  # vllm-8-archfunction
  - model_name: katanemo/Arch-Function-7B
    litellm_params:
      model: openai/katanemo/Arch-Function-7B
      api_base: http://vllm-8-archfunction:8000/v1
      api_key: none

general_settings:
  master_key: 'sk-blacklight-key'
